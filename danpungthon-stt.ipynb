{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "d7fcc339-2ba9-441b-8586-949040d9eacb",
    "_uuid": "921e208c-2f94-45a6-95ee-1808ac3a1c23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-23T12:09:32.859534Z",
     "iopub.status.busy": "2024-11-23T12:09:32.858578Z",
     "iopub.status.idle": "2024-11-23T12:09:58.120006Z",
     "shell.execute_reply": "2024-11-23T12:09:58.119022Z",
     "shell.execute_reply.started": "2024-11-23T12:09:32.859498Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\lg\\appdata\\local\\temp\\pip-req-build-wdwoyy7k\n",
      "  Resolved https://github.com/openai/whisper.git to commit 173ff7dd1d9fb1c4fddea0d41d704cfefeb8908c\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numba in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (2.0.2)\n",
      "Requirement already satisfied: torch in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai-whisper==20240930) (0.8.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tqdm->openai-whisper==20240930) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\LG\\AppData\\Local\\Temp\\pip-req-build-wdwoyy7k'\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:09:58.121956Z",
     "iopub.status.busy": "2024-11-23T12:09:58.121644Z",
     "iopub.status.idle": "2024-11-23T12:10:06.443552Z",
     "shell.execute_reply": "2024-11-23T12:10:06.442555Z",
     "shell.execute_reply.started": "2024-11-23T12:09:58.121925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:08:59.556068Z",
     "iopub.status.busy": "2024-11-23T12:08:59.555610Z",
     "iopub.status.idle": "2024-11-23T12:09:09.590248Z",
     "shell.execute_reply": "2024-11-23T12:09:09.589200Z",
     "shell.execute_reply.started": "2024-11-23T12:08:59.556014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (1.55.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통화 녹음 stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:10:06.445073Z",
     "iopub.status.busy": "2024-11-23T12:10:06.444778Z",
     "iopub.status.idle": "2024-11-23T12:11:05.569447Z",
     "shell.execute_reply": "2024-11-23T12:11:05.568469Z",
     "shell.execute_reply.started": "2024-11-23T12:10:06.445042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2.88G/2.88G [00:16<00:00, 190MiB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "Processing Audio File: 100%|██████████| 1/1 [00:08<00:00,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription Result:\n",
      " 안녕하세요 네 반갑습니다 오십울 팀 멘토 오자연입니다 이번에 면접 준비하여서 관련된 소프트 스킬에 대한 내용을 알아보고 싶었어요 네 제가 대답할 수 있는 것에 대해서 성심성의껏 알려드리도록 하겠습니다 혹시 앞 면접에서 어려운 질문이 나와서 대답을 못하는 상황이 오더라도 확실하게 그 부분은 부족하다고 당당하게 이야기하는 것이 중요합니다 자기가 가지고 있는 역량을 확실하게 파악하고 있다는 것도 하나의 플러스 요인이 될 수 있거든요 아 그렇군요 감사합니다 네 제가 도움을 줄 수 있어 기쁩니다 네 제가 도움을 줄 수 있어 기쁩니다 감사합니다 감사합니다\n",
      "\n",
      "Transcription saved to: /kaggle/working/full_result.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Whisper 모델 로드\n",
    "model = whisper.load_model(\"large\", device=\"cuda:0\")  # 'large' 모델을 GPU에서 로드\n",
    "\n",
    "# 파일 경로 지정\n",
    "file_path = \"/kaggle/input/danpung-test/danpungthon_test_mentoring_data.mp3\"\n",
    "\n",
    "# 저장할 .txt 파일 경로\n",
    "output_txt_path = \"/kaggle/working/full_result.txt\"\n",
    "\n",
    "# TQDM 진행 표시\n",
    "with tqdm(total=1, desc=\"Processing Audio File\") as pbar:\n",
    "    try:\n",
    "        # STT 변환\n",
    "        result = model.transcribe(file_path, fp16=False)  # fp16=False로 설정하여 안정성 확보\n",
    "        pbar.update(1)  # 진행 상황 업데이트\n",
    "\n",
    "        # 변환된 텍스트\n",
    "        transcribed_text = result['text']\n",
    "        print(\"\\nTranscription Result:\")\n",
    "        print(transcribed_text)  # 변환된 텍스트 출력\n",
    "\n",
    "        # 텍스트 파일로 저장\n",
    "        with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(transcribed_text)\n",
    "        print(f\"\\nTranscription saved to: {output_txt_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        pbar.update(1)  # 오류 발생 시에도 진행 상태 업데이트\n",
    "        print(\"\\nError during transcription:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T09:37:51.721512Z",
     "iopub.status.busy": "2024-11-23T09:37:51.721180Z",
     "iopub.status.idle": "2024-11-23T09:38:42.812157Z",
     "shell.execute_reply": "2024-11-23T09:38:42.811261Z",
     "shell.execute_reply.started": "2024-11-23T09:37:51.721483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Transcription:\n",
      " 안녕하세요  네 반갑습니다. 오시불 팀 멘토 오자연입니다.  이번에 면접을 준비해서 관련된 소프트 스킬에 대한 내용을 알아보고 싶었어요.  네 제가 대답할 수 있는 것에 대해서 성심성의껏 알려드리도록 하겠습니다  혹시 압박 면접에서 어려운 질문이 나와서 대답을 못하는 상황이 오더라도 확실하게 그 부분은 부족하다고 당당하게 이야기하는 것이 중요합니다 자기가 가지고 있는 역량을 확실하게 파악하고 있다는 것도 하나의 플러스 요인이 될 수 있거든요  아 그렇군요. 감사합니다.  네 제가 도움을 줄 수 있어  Thank you.  감사합니다. \n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import whisper\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# # GPU 메모리 초기화\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Whisper 모델 로드\n",
    "# model = whisper.load_model(\"large\", device=\"cuda:0\")  # 'large' 모델을 GPU에서 로드\n",
    "\n",
    "# # 파일 경로 지정\n",
    "# file_path = \"/kaggle/input/danpung-test/danpungthon_test_mentoring_data.mp3\"\n",
    "\n",
    "# # 오디오 로드\n",
    "# audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "# # Whisper 모델로 전체 파일 변환 (문장 경계 추출)\n",
    "# result = model.transcribe(file_path, fp16=False)\n",
    "\n",
    "# # 문장 단위로 오디오 분할 및 정확도 향상 처리\n",
    "# transcribed_text = []\n",
    "# for segment in result['segments']:\n",
    "#     start = segment['start']  # 문장 시작 시간 (초)\n",
    "#     end = segment['end']      # 문장 끝 시간 (초)\n",
    "\n",
    "#     # 오디오에서 해당 문장 부분 잘라내기\n",
    "#     audio_segment = audio[start * 1000:end * 1000]  # 초 단위를 밀리초로 변환\n",
    "\n",
    "#     # 잘라낸 오디오를 임시 파일로 저장 (Whisper는 파일 입력 필요)\n",
    "#     temp_path = \"temp_audio_segment.wav\"\n",
    "#     audio_segment.export(temp_path, format=\"wav\")\n",
    "\n",
    "#     # Whisper로 문장 단위 STT 수행 (문장 경계 재확인 및 STT)\n",
    "#     segment_result = model.transcribe(temp_path, fp16=False)\n",
    "#     transcribed_text.append(segment_result['text'])  # 개별 문장을 결과 리스트에 추가\n",
    "\n",
    "# # 변환된 모든 문장을 하나로 합치기\n",
    "# final_text = \" \".join(transcribed_text)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"Final Transcription:\")\n",
    "# print(final_text)\n",
    "\n",
    "# # 결과를 텍스트 파일로 저장\n",
    "# output_txt_path = \"/kaggle/working/transcription_result.txt\"\n",
    "# with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "#     txt_file.write(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T09:49:45.156193Z",
     "iopub.status.busy": "2024-11-23T09:49:45.155832Z",
     "iopub.status.idle": "2024-11-23T09:50:20.327820Z",
     "shell.execute_reply": "2024-11-23T09:50:20.326941Z",
     "shell.execute_reply.started": "2024-11-23T09:49:45.156163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "Processing Audio File: 100%|██████████| 1/1 [00:06<00:00,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcription Result:\n",
      " 안녕하세요 네 반갑습니다 오십울 팀 멘토 오자연입니다 이번에 면접 준비하여서 관련된 소프트 스킬에 대한 내용을 알아보고 싶었어요 네 제가 대답할 수 있는 것에 대해서 성심성의껏 알려드리도록 하겠습니다 혹시 앞 면접에서 어려운 질문이 나와서 대답을 못하는 상황이 오더라도 확실하게 그 부분은 부족하다고 당당하게 이야기하는 것이 중요합니다 자기가 가지고 있는 역량을 확실하게 파악하고 있다는 것도 하나의 플러스 요인이 될 수 있거든요 아 그렇군요 감사합니다 네 제가 도움을 줄 수 있어 기쁩니다 네 제가 도움을 줄 수 있어 기쁩니다 감사합니다 감사합니다\n",
      "\n",
      "Transcription saved to: /kaggle/working/stt_sentence_2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Whisper 모델 로드\n",
    "model = whisper.load_model(\"large\", device=\"cuda:0\")  # 'large' 모델을 GPU에서 로드\n",
    "\n",
    "# 파일 경로 지정\n",
    "file_path = \"/kaggle/input/danpung-test/danpungthon_test_mentoring_data.mp3\"\n",
    "\n",
    "# 저장할 .txt 파일 경로\n",
    "output_txt_path = \"/kaggle/working/stt_sentence_2.txt\"\n",
    "\n",
    "# TQDM 진행 표시\n",
    "with tqdm(total=1, desc=\"Processing Audio File\") as pbar:\n",
    "    try:\n",
    "        # STT 변환 (문장 단위로 처리)\n",
    "        result = model.transcribe(file_path, fp16=False)  # Whisper 모델로 전체 오디오 파일 변환\n",
    "        pbar.update(1)  # 진행 상태 업데이트\n",
    "\n",
    "        # 변환된 텍스트를 문장 단위로 처리 (시간 정보 제외)\n",
    "        full_transcription = \"\".join(segment['text'] for segment in result['segments'])\n",
    "\n",
    "        # 변환된 텍스트 출력\n",
    "        print(\"\\nTranscription Result:\")\n",
    "        print(full_transcription)\n",
    "\n",
    "        # 텍스트 파일로 저장\n",
    "        with open(output_txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(full_transcription)\n",
    "        print(f\"\\nTranscription saved to: {output_txt_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        pbar.update(1)  # 오류 발생 시에도 진행 상태 업데이트\n",
    "        print(\"\\nError during transcription:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추출한 텍스트 cer 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:11:17.203621Z",
     "iopub.status.busy": "2024-11-23T12:11:17.202884Z",
     "iopub.status.idle": "2024-11-23T12:11:27.227118Z",
     "shell.execute_reply": "2024-11-23T12:11:27.225934Z",
     "shell.execute_reply.started": "2024-11-23T12:11:17.203585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting click<9.0.0,>=8.1.3 (from jiwer)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.4 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, click, jiwer\n",
      "Successfully installed click-8.1.7 jiwer-3.0.5 rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T09:50:34.116593Z",
     "iopub.status.busy": "2024-11-23T09:50:34.115765Z",
     "iopub.status.idle": "2024-11-23T09:50:34.125761Z",
     "shell.execute_reply": "2024-11-23T09:50:34.124920Z",
     "shell.execute_reply.started": "2024-11-23T09:50:34.116556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate (CER): 2.62%\n",
      "Character Error Rate (CER): 2.62%\n"
     ]
    }
   ],
   "source": [
    "from jiwer import cer\n",
    "\n",
    "# STT 결과 파일 경로\n",
    "stt_result_path_1 = \"/kaggle/working/full_result.txt\"\n",
    "#stt_result_path_2 = \"/kaggle/working/transcription_result.txt\"\n",
    "stt_result_path_3 = \"/kaggle/working/stt_sentence_2.txt\"\n",
    "\n",
    "# 정답 파일 경로\n",
    "ground_truth_path = \"/kaggle/input/danpung-test/transcription_result (1).txt\"\n",
    "\n",
    "# 파일 읽기\n",
    "with open(stt_result_path_1, \"r\", encoding=\"utf-8\") as stt_file:\n",
    "    stt_text_1 = stt_file.read()\n",
    "\n",
    "# # 파일 읽기\n",
    "# with open(stt_result_path_2, \"r\", encoding=\"utf-8\") as stt_file:\n",
    "#     stt_text_2 = stt_file.read()\n",
    "\n",
    "# 파일 읽기\n",
    "with open(stt_result_path_3, \"r\", encoding=\"utf-8\") as stt_file:\n",
    "    stt_text_3 = stt_file.read()\n",
    "\n",
    "\n",
    "\n",
    "with open(ground_truth_path, \"r\", encoding=\"utf-8\") as gt_file:\n",
    "    ground_truth_text = gt_file.read()\n",
    "\n",
    "# CER 계산\n",
    "character_error_rate_1 = cer(ground_truth_text, stt_text_1)\n",
    "#character_error_rate_2 = cer(ground_truth_text, stt_text_2)\n",
    "character_error_rate_3 = cer(ground_truth_text, stt_text_3)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Character Error Rate (CER): {character_error_rate_1:.2%}\")\n",
    "# print(f\"Character Error Rate (CER): {character_error_rate_2:.2%}\")\n",
    "print(f\"Character Error Rate (CER): {character_error_rate_3:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
    "    message = [{'role': 'user', 'content': prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=message,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약본 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:29:09.078061Z",
     "iopub.status.busy": "2024-11-23T12:29:09.077318Z",
     "iopub.status.idle": "2024-11-23T12:29:17.405148Z",
     "shell.execute_reply": "2024-11-23T12:29:17.404196Z",
     "shell.execute_reply.started": "2024-11-23T12:29:09.078029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.1-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lg\\anaconda3\\envs\\anaconda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.7.1-cp311-none-win_amd64.whl (203 kB)\n",
      "Downloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jiter-0.7.1 openai-1.55.0 pydantic-2.10.1 pydantic-core-2.27.1 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:23.737415Z",
     "iopub.status.busy": "2024-11-23T13:23:23.737013Z",
     "iopub.status.idle": "2024-11-23T13:23:23.748792Z",
     "shell.execute_reply": "2024-11-23T13:23:23.747773Z",
     "shell.execute_reply.started": "2024-11-23T13:23:23.737377Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summary...\n",
      "Error generating summary: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Summary saved to C:/Users/LG/Desktop/2024/2024_2학기/단풍톤/final_text.txt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = \"\"  \n",
    "\n",
    "def get_summary(text, model=\"gpt-3.5-turbo\"):\n",
    "    prompt = f\"\"\"\n",
    "    너가 해야하는 일은 아래 주어진 text를 보고 요약본을 생성하는 거야. 아래 텍스트에서 주요한 내용을 판단하고 추려서 요약해줘. 중요한 키워드 중심으로 한 문장씩 이루어지는 형식으로 요약본을 만들어줘. 다른 말은 필요없이 요약본만 결과물로 표시해줘.\n",
    "    \n",
    "\n",
    "    텍스트:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "        summary = response.choices[0].message['content']\n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return \"요약 실패\"\n",
    "\n",
    "# 파일 경로 설정\n",
    "input_file_path = \"C:/Users/LG/Desktop/2024/2024_2학기/단풍톤/full_result.txt\"\n",
    "output_file_path = \"C:/Users/LG/Desktop/2024/2024_2학기/단풍톤/final_text.txt\"\n",
    "\n",
    "# 입력 파일 읽기\n",
    "try:\n",
    "    with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        full_text = file.read()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading input file: {e}\")\n",
    "    full_text = \"\"\n",
    "\n",
    "# 요약 생성\n",
    "if full_text.strip():\n",
    "    print(\"Generating summary...\")\n",
    "    final_text = get_summary(full_text)\n",
    "\n",
    "    # 요약본 저장\n",
    "    try:\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(final_text)\n",
    "        print(f\"Summary saved to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary: {e}\")\n",
    "else:\n",
    "    print(\"Input text is empty. No summary generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4736329,
     "sourceId": 8034777,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6148047,
     "sourceId": 9989881,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "anaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
